{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\risha\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import LSTM,Embedding,Dense,Input\n",
    "from keras.models import  Model\n",
    "from keras.optimizers import Adam,SGD\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import string\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SEQUENCE_LEN =100\n",
    "MAX_VOCAB_LEN = 3000\n",
    "EMBEDDING_DIM = 50\n",
    "VALIDATION_SPLIT = 0.2\n",
    "EPOCHS = 2000\n",
    "BATCH_SIZE = 128\n",
    "LATENT_DIM = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_texts = []\n",
    "target_texts = []\n",
    "for line in open('robert_frost.txt'):\n",
    "    line = line.rstrip()\n",
    "    if not line:\n",
    "        continue\n",
    "\n",
    "    input_line = '<sos> ' + line\n",
    "    target_line = line + ' <eos>'\n",
    "\n",
    "    input_texts.append(input_line)\n",
    "    target_texts.append(target_line)\n",
    "    \n",
    "all_lines = input_texts + target_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=MAX_VOCAB_LEN,filters='')\n",
    "tokenizer.fit_on_texts(all_lines)\n",
    "ip_seq = tokenizer.texts_to_sequences(input_texts)\n",
    "op_seq = tokenizer.texts_to_sequences(target_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_seq_len_from_data = max(len(s)for s in ip_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_seq_len_from_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2idx = tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert('<sos>' in word2idx)\n",
    "assert('<eos>' in word2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3056"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_seq_len = min(max_seq_len_from_data,MAX_SEQUENCE_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_seq_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "ip_seq = pad_sequences(ip_seq,maxlen=max_seq_len,padding='post')\n",
    "op_seq = pad_sequences(ip_seq,maxlen = max_seq_len,padding = 'post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading word vectors...\n",
      "Found 400000 word vectors.\n"
     ]
    }
   ],
   "source": [
    "print('Loading word vectors...')\n",
    "word2vec = {}\n",
    "with open(os.path.join('../all (1)/large_files/glove.6B/glove.6B.%sd.txt' % EMBEDDING_DIM),encoding=\"utf8\") as f:\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        vec = np.asarray(values[1:], dtype='float32')\n",
    "        word2vec[word] = vec\n",
    "print('Found %s word vectors.' % len(word2vec))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filling pre-trained embeddings...\n"
     ]
    }
   ],
   "source": [
    "print('Filling pre-trained embeddings...')\n",
    "num_words = min(MAX_VOCAB_LEN, len(word2idx) + 1)\n",
    "embedding_matrix = np.zeros((num_words, EMBEDDING_DIM))\n",
    "for word, i in word2idx.items():\n",
    "    if i < MAX_VOCAB_LEN:\n",
    "        embedding_vector = word2vec.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            # words not found in embedding index will be all zeros.\n",
    "            embedding_matrix[i] = embedding_vector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_targets = np.zeros((len(ip_seq), max_seq_len, num_words))\n",
    "for i, op_seq in enumerate(op_seq):\n",
    "    for t, word in enumerate(op_seq):\n",
    "        if word > 0:\n",
    "            one_hot_targets[i, t, word] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "embd_layer = Embedding(num_words,EMBEDDING_DIM,weights = [embedding_matrix],trainable=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building Model\n"
     ]
    }
   ],
   "source": [
    "print('Building Model')\n",
    "\n",
    "ip_ = Input(shape=(max_seq_len,))\n",
    "init_h = Input(shape=(LATENT_DIM,))\n",
    "init_c = Input(shape=(LATENT_DIM,))\n",
    "x = embd_layer(ip_)\n",
    "lstm = LSTM(LATENT_DIM,return_sequences=True,return_state=True)\n",
    "x,_,_ = lstm(x,initial_state = [init_h,init_c])\n",
    "dense = Dense(num_words,activation='softmax')\n",
    "op = dense(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model([ip_,init_h,init_c],op)\n",
    "model.compile(loss='categorical_crossentropy',optimizer = Adam(lr=0.01),metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1148 samples, validate on 288 samples\n",
      "Epoch 1/100\n",
      "1148/1148 [==============================] - 12s 11ms/step - loss: 5.3758 - acc: 0.0021 - val_loss: 5.1006 - val_acc: 0.0014\n",
      "Epoch 2/100\n",
      "1148/1148 [==============================] - 9s 8ms/step - loss: 4.7712 - acc: 0.0146 - val_loss: 5.0241 - val_acc: 0.0220\n",
      "Epoch 3/100\n",
      "1148/1148 [==============================] - 9s 8ms/step - loss: 4.5608 - acc: 0.0333 - val_loss: 4.8725 - val_acc: 0.0226\n",
      "Epoch 4/100\n",
      "1148/1148 [==============================] - 9s 8ms/step - loss: 4.4209 - acc: 0.0703 - val_loss: 4.7381 - val_acc: 0.1059\n",
      "Epoch 5/100\n",
      "1148/1148 [==============================] - 9s 8ms/step - loss: 4.3066 - acc: 0.1168 - val_loss: 4.6222 - val_acc: 0.1059\n",
      "Epoch 6/100\n",
      "1148/1148 [==============================] - 9s 8ms/step - loss: 4.2041 - acc: 0.1167 - val_loss: 4.5244 - val_acc: 0.1059\n",
      "Epoch 7/100\n",
      "1148/1148 [==============================] - 9s 8ms/step - loss: 4.0820 - acc: 0.1167 - val_loss: 4.4123 - val_acc: 0.1073\n",
      "Epoch 8/100\n",
      "1148/1148 [==============================] - 9s 8ms/step - loss: 3.9285 - acc: 0.1190 - val_loss: 4.2719 - val_acc: 0.1131\n",
      "Epoch 9/100\n",
      "1148/1148 [==============================] - 9s 8ms/step - loss: 3.7294 - acc: 0.1280 - val_loss: 4.0824 - val_acc: 0.1314\n",
      "Epoch 10/100\n",
      "1148/1148 [==============================] - 9s 8ms/step - loss: 3.4791 - acc: 0.1446 - val_loss: 3.8439 - val_acc: 0.1435\n",
      "Epoch 11/100\n",
      "1148/1148 [==============================] - 9s 8ms/step - loss: 3.2042 - acc: 0.1677 - val_loss: 3.6263 - val_acc: 0.1696\n",
      "Epoch 12/100\n",
      "1148/1148 [==============================] - 9s 8ms/step - loss: 2.9703 - acc: 0.2048 - val_loss: 3.4614 - val_acc: 0.1991\n",
      "Epoch 13/100\n",
      "1148/1148 [==============================] - 9s 8ms/step - loss: 2.7724 - acc: 0.2483 - val_loss: 3.3226 - val_acc: 0.2329\n",
      "Epoch 14/100\n",
      "1148/1148 [==============================] - 9s 7ms/step - loss: 2.5903 - acc: 0.2837 - val_loss: 3.1999 - val_acc: 0.2624\n",
      "Epoch 15/100\n",
      "1148/1148 [==============================] - 8s 7ms/step - loss: 2.4221 - acc: 0.3153 - val_loss: 3.0955 - val_acc: 0.2873\n",
      "Epoch 16/100\n",
      "1148/1148 [==============================] - 9s 7ms/step - loss: 2.2714 - acc: 0.3437 - val_loss: 3.0020 - val_acc: 0.3102\n",
      "Epoch 17/100\n",
      "1148/1148 [==============================] - 8s 7ms/step - loss: 2.1315 - acc: 0.3711 - val_loss: 2.9208 - val_acc: 0.3411\n",
      "Epoch 18/100\n",
      "1148/1148 [==============================] - 8s 7ms/step - loss: 2.0057 - acc: 0.3908 - val_loss: 2.8471 - val_acc: 0.3547\n",
      "Epoch 19/100\n",
      "1148/1148 [==============================] - 8s 7ms/step - loss: 1.8912 - acc: 0.4061 - val_loss: 2.7856 - val_acc: 0.3698\n",
      "Epoch 20/100\n",
      "1148/1148 [==============================] - 9s 7ms/step - loss: 1.7859 - acc: 0.4244 - val_loss: 2.7293 - val_acc: 0.3903\n",
      "Epoch 21/100\n",
      "1148/1148 [==============================] - 8s 7ms/step - loss: 1.6913 - acc: 0.4398 - val_loss: 2.6856 - val_acc: 0.4022\n",
      "Epoch 22/100\n",
      "1148/1148 [==============================] - 8s 7ms/step - loss: 1.6031 - acc: 0.4525 - val_loss: 2.6459 - val_acc: 0.4115\n",
      "Epoch 23/100\n",
      "1148/1148 [==============================] - 9s 8ms/step - loss: 1.5235 - acc: 0.4644 - val_loss: 2.6129 - val_acc: 0.4207\n",
      "Epoch 24/100\n",
      "1148/1148 [==============================] - 9s 8ms/step - loss: 1.4500 - acc: 0.4765 - val_loss: 2.5813 - val_acc: 0.4280\n",
      "Epoch 25/100\n",
      "1148/1148 [==============================] - 9s 7ms/step - loss: 1.3825 - acc: 0.4858 - val_loss: 2.5566 - val_acc: 0.4369\n",
      "Epoch 26/100\n",
      "1148/1148 [==============================] - 8s 7ms/step - loss: 1.3202 - acc: 0.4951 - val_loss: 2.5382 - val_acc: 0.4416\n",
      "Epoch 27/100\n",
      "1148/1148 [==============================] - 9s 8ms/step - loss: 1.2618 - acc: 0.5034 - val_loss: 2.5204 - val_acc: 0.4479\n",
      "Epoch 28/100\n",
      "1148/1148 [==============================] - 8s 7ms/step - loss: 1.2068 - acc: 0.5116 - val_loss: 2.5055 - val_acc: 0.4505\n",
      "Epoch 29/100\n",
      "1148/1148 [==============================] - 8s 7ms/step - loss: 1.1561 - acc: 0.5202 - val_loss: 2.4922 - val_acc: 0.4543\n",
      "Epoch 30/100\n",
      "1148/1148 [==============================] - 8s 7ms/step - loss: 1.1084 - acc: 0.5282 - val_loss: 2.4792 - val_acc: 0.4563\n",
      "Epoch 31/100\n",
      "1148/1148 [==============================] - 8s 7ms/step - loss: 1.0629 - acc: 0.5371 - val_loss: 2.4760 - val_acc: 0.4615\n",
      "Epoch 32/100\n",
      "1148/1148 [==============================] - 8s 7ms/step - loss: 1.0215 - acc: 0.5449 - val_loss: 2.4682 - val_acc: 0.4641\n",
      "Epoch 33/100\n",
      "1148/1148 [==============================] - 8s 7ms/step - loss: 0.9810 - acc: 0.5520 - val_loss: 2.4637 - val_acc: 0.4667\n",
      "Epoch 34/100\n",
      "1148/1148 [==============================] - 8s 7ms/step - loss: 0.9433 - acc: 0.5598 - val_loss: 2.4589 - val_acc: 0.4679\n",
      "Epoch 35/100\n",
      "1148/1148 [==============================] - 8s 7ms/step - loss: 0.9083 - acc: 0.5666 - val_loss: 2.4562 - val_acc: 0.4711\n",
      "Epoch 36/100\n",
      "1148/1148 [==============================] - 10s 9ms/step - loss: 0.8752 - acc: 0.5724 - val_loss: 2.4527 - val_acc: 0.4716\n",
      "Epoch 37/100\n",
      "1148/1148 [==============================] - 8s 7ms/step - loss: 0.8446 - acc: 0.5778 - val_loss: 2.4511 - val_acc: 0.4754\n",
      "Epoch 38/100\n",
      "1148/1148 [==============================] - 8s 7ms/step - loss: 0.8151 - acc: 0.5825 - val_loss: 2.4500 - val_acc: 0.4769\n",
      "Epoch 39/100\n",
      "1148/1148 [==============================] - 8s 7ms/step - loss: 0.7874 - acc: 0.5861 - val_loss: 2.4486 - val_acc: 0.4789\n",
      "Epoch 40/100\n",
      "1148/1148 [==============================] - 8s 7ms/step - loss: 0.7610 - acc: 0.5902 - val_loss: 2.4518 - val_acc: 0.4795\n",
      "Epoch 41/100\n",
      "1148/1148 [==============================] - 8s 7ms/step - loss: 0.7361 - acc: 0.5938 - val_loss: 2.4499 - val_acc: 0.4803\n",
      "Epoch 42/100\n",
      "1148/1148 [==============================] - 8s 7ms/step - loss: 0.7132 - acc: 0.5968 - val_loss: 2.4534 - val_acc: 0.4829\n",
      "Epoch 43/100\n",
      "1148/1148 [==============================] - 9s 8ms/step - loss: 0.6910 - acc: 0.5997 - val_loss: 2.4545 - val_acc: 0.4852\n",
      "Epoch 44/100\n",
      "1148/1148 [==============================] - 8s 7ms/step - loss: 0.6704 - acc: 0.6020 - val_loss: 2.4563 - val_acc: 0.4841\n",
      "Epoch 45/100\n",
      "1148/1148 [==============================] - 8s 7ms/step - loss: 0.6509 - acc: 0.6042 - val_loss: 2.4589 - val_acc: 0.4861\n",
      "Epoch 46/100\n",
      "1148/1148 [==============================] - 9s 8ms/step - loss: 0.6332 - acc: 0.6065 - val_loss: 2.4623 - val_acc: 0.4884\n",
      "Epoch 47/100\n",
      "1148/1148 [==============================] - 9s 7ms/step - loss: 0.6163 - acc: 0.6087 - val_loss: 2.4651 - val_acc: 0.4890\n",
      "Epoch 48/100\n",
      "1148/1148 [==============================] - 8s 7ms/step - loss: 0.6001 - acc: 0.6112 - val_loss: 2.4697 - val_acc: 0.4905\n",
      "Epoch 49/100\n",
      "1148/1148 [==============================] - 8s 7ms/step - loss: 0.5846 - acc: 0.6135 - val_loss: 2.4706 - val_acc: 0.4910\n",
      "Epoch 50/100\n",
      "1148/1148 [==============================] - 8s 7ms/step - loss: 0.5707 - acc: 0.6146 - val_loss: 2.4766 - val_acc: 0.4919\n",
      "Epoch 51/100\n",
      "1148/1148 [==============================] - 8s 7ms/step - loss: 0.5570 - acc: 0.6165 - val_loss: 2.4801 - val_acc: 0.4913\n",
      "Epoch 52/100\n",
      "1148/1148 [==============================] - 8s 7ms/step - loss: 0.5437 - acc: 0.6175 - val_loss: 2.4865 - val_acc: 0.4925\n",
      "Epoch 53/100\n",
      "1148/1148 [==============================] - 8s 7ms/step - loss: 0.5307 - acc: 0.6195 - val_loss: 2.4908 - val_acc: 0.4916\n",
      "Epoch 54/100\n",
      "1148/1148 [==============================] - 10s 9ms/step - loss: 0.5189 - acc: 0.6216 - val_loss: 2.4945 - val_acc: 0.4913\n",
      "Epoch 55/100\n",
      "1148/1148 [==============================] - 9s 8ms/step - loss: 0.5075 - acc: 0.6236 - val_loss: 2.4988 - val_acc: 0.4925\n",
      "Epoch 56/100\n",
      "1148/1148 [==============================] - 9s 8ms/step - loss: 0.4966 - acc: 0.6246 - val_loss: 2.5016 - val_acc: 0.4928\n",
      "Epoch 57/100\n",
      "1148/1148 [==============================] - 8s 7ms/step - loss: 0.4862 - acc: 0.6262 - val_loss: 2.5068 - val_acc: 0.4913\n",
      "Epoch 58/100\n",
      "1148/1148 [==============================] - 9s 8ms/step - loss: 0.4761 - acc: 0.6273 - val_loss: 2.5114 - val_acc: 0.4922\n",
      "Epoch 59/100\n",
      "1148/1148 [==============================] - 9s 7ms/step - loss: 0.4666 - acc: 0.6299 - val_loss: 2.5145 - val_acc: 0.4933\n",
      "Epoch 60/100\n",
      "1148/1148 [==============================] - 9s 8ms/step - loss: 0.4572 - acc: 0.6311 - val_loss: 2.5227 - val_acc: 0.4922\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/100\n",
      "1148/1148 [==============================] - 9s 7ms/step - loss: 0.4485 - acc: 0.6307 - val_loss: 2.5262 - val_acc: 0.4925\n",
      "Epoch 62/100\n",
      "1148/1148 [==============================] - 10s 8ms/step - loss: 0.4402 - acc: 0.6331 - val_loss: 2.5278 - val_acc: 0.4925\n",
      "Epoch 63/100\n",
      "1148/1148 [==============================] - 9s 7ms/step - loss: 0.4325 - acc: 0.6340 - val_loss: 2.5324 - val_acc: 0.4945\n",
      "Epoch 64/100\n",
      "1148/1148 [==============================] - 8s 7ms/step - loss: 0.4245 - acc: 0.6337 - val_loss: 2.5387 - val_acc: 0.4931\n",
      "Epoch 65/100\n",
      "1148/1148 [==============================] - 8s 7ms/step - loss: 0.4165 - acc: 0.6352 - val_loss: 2.5456 - val_acc: 0.4931\n",
      "Epoch 66/100\n",
      "1148/1148 [==============================] - 8s 7ms/step - loss: 0.4090 - acc: 0.6370 - val_loss: 2.5501 - val_acc: 0.4919\n",
      "Epoch 67/100\n",
      "1148/1148 [==============================] - 8s 7ms/step - loss: 0.4016 - acc: 0.6373 - val_loss: 2.5545 - val_acc: 0.4931\n",
      "Epoch 68/100\n",
      "1148/1148 [==============================] - 8s 7ms/step - loss: 0.3946 - acc: 0.6394 - val_loss: 2.5571 - val_acc: 0.4931\n",
      "Epoch 69/100\n",
      "1148/1148 [==============================] - 8s 7ms/step - loss: 0.3881 - acc: 0.6397 - val_loss: 2.5634 - val_acc: 0.4939\n",
      "Epoch 70/100\n",
      "1148/1148 [==============================] - 8s 7ms/step - loss: 0.3817 - acc: 0.6412 - val_loss: 2.5654 - val_acc: 0.4933\n",
      "Epoch 71/100\n",
      "1148/1148 [==============================] - 8s 7ms/step - loss: 0.3753 - acc: 0.6418 - val_loss: 2.5727 - val_acc: 0.4936\n",
      "Epoch 72/100\n",
      "1148/1148 [==============================] - 9s 8ms/step - loss: 0.3694 - acc: 0.6425 - val_loss: 2.5748 - val_acc: 0.4942\n",
      "Epoch 73/100\n",
      "1148/1148 [==============================] - 9s 8ms/step - loss: 0.3638 - acc: 0.6431 - val_loss: 2.5820 - val_acc: 0.4933\n",
      "Epoch 74/100\n",
      "1148/1148 [==============================] - 9s 8ms/step - loss: 0.3583 - acc: 0.6443 - val_loss: 2.5851 - val_acc: 0.4933\n",
      "Epoch 75/100\n",
      "1148/1148 [==============================] - 10s 9ms/step - loss: 0.3523 - acc: 0.6447 - val_loss: 2.5902 - val_acc: 0.4951\n",
      "Epoch 76/100\n",
      "1148/1148 [==============================] - 11s 9ms/step - loss: 0.3469 - acc: 0.6463 - val_loss: 2.5942 - val_acc: 0.4942\n",
      "Epoch 77/100\n",
      "1148/1148 [==============================] - 10s 9ms/step - loss: 0.3420 - acc: 0.6461 - val_loss: 2.5978 - val_acc: 0.4936\n",
      "Epoch 78/100\n",
      "1148/1148 [==============================] - 10s 9ms/step - loss: 0.3367 - acc: 0.6463 - val_loss: 2.6008 - val_acc: 0.4945\n",
      "Epoch 79/100\n",
      "1148/1148 [==============================] - 10s 9ms/step - loss: 0.3317 - acc: 0.6476 - val_loss: 2.6051 - val_acc: 0.4939\n",
      "Epoch 80/100\n",
      "1148/1148 [==============================] - 10s 8ms/step - loss: 0.3271 - acc: 0.6492 - val_loss: 2.6111 - val_acc: 0.4939\n",
      "Epoch 81/100\n",
      "1148/1148 [==============================] - 10s 9ms/step - loss: 0.3231 - acc: 0.6493 - val_loss: 2.6109 - val_acc: 0.4945\n",
      "Epoch 82/100\n",
      "1148/1148 [==============================] - 9s 8ms/step - loss: 0.3183 - acc: 0.6489 - val_loss: 2.6145 - val_acc: 0.4948\n",
      "Epoch 83/100\n",
      "1148/1148 [==============================] - 9s 7ms/step - loss: 0.3138 - acc: 0.6505 - val_loss: 2.6208 - val_acc: 0.4957\n",
      "Epoch 84/100\n",
      "1148/1148 [==============================] - 9s 8ms/step - loss: 0.3094 - acc: 0.6511 - val_loss: 2.6223 - val_acc: 0.4954\n",
      "Epoch 85/100\n",
      "1148/1148 [==============================] - 8s 7ms/step - loss: 0.3052 - acc: 0.6508 - val_loss: 2.6223 - val_acc: 0.4948\n",
      "Epoch 86/100\n",
      "1148/1148 [==============================] - 9s 7ms/step - loss: 0.3006 - acc: 0.6514 - val_loss: 2.6294 - val_acc: 0.4945\n",
      "Epoch 87/100\n",
      "1148/1148 [==============================] - 9s 7ms/step - loss: 0.2963 - acc: 0.6536 - val_loss: 2.6325 - val_acc: 0.4945\n",
      "Epoch 88/100\n",
      "1148/1148 [==============================] - 9s 8ms/step - loss: 0.2931 - acc: 0.6532 - val_loss: 2.6340 - val_acc: 0.4957\n",
      "Epoch 89/100\n",
      "1148/1148 [==============================] - 9s 8ms/step - loss: 0.2896 - acc: 0.6531 - val_loss: 2.6359 - val_acc: 0.4957\n",
      "Epoch 90/100\n",
      "1148/1148 [==============================] - 9s 8ms/step - loss: 0.2853 - acc: 0.6545 - val_loss: 2.6399 - val_acc: 0.4942\n",
      "Epoch 91/100\n",
      "1148/1148 [==============================] - 10s 8ms/step - loss: 0.2819 - acc: 0.6543 - val_loss: 2.6443 - val_acc: 0.4951\n",
      "Epoch 92/100\n",
      "1148/1148 [==============================] - 9s 8ms/step - loss: 0.2794 - acc: 0.6549 - val_loss: 2.6444 - val_acc: 0.4957\n",
      "Epoch 93/100\n",
      "1148/1148 [==============================] - 9s 8ms/step - loss: 0.2750 - acc: 0.6561 - val_loss: 2.6486 - val_acc: 0.4951\n",
      "Epoch 94/100\n",
      "1148/1148 [==============================] - 11s 10ms/step - loss: 0.2715 - acc: 0.6565 - val_loss: 2.6505 - val_acc: 0.4951\n",
      "Epoch 95/100\n",
      "1148/1148 [==============================] - 11s 10ms/step - loss: 0.2681 - acc: 0.6574 - val_loss: 2.6539 - val_acc: 0.4957\n",
      "Epoch 96/100\n",
      "1148/1148 [==============================] - 10s 9ms/step - loss: 0.2651 - acc: 0.6572 - val_loss: 2.6575 - val_acc: 0.4957\n",
      "Epoch 97/100\n",
      "1148/1148 [==============================] - 10s 9ms/step - loss: 0.2615 - acc: 0.6582 - val_loss: 2.6590 - val_acc: 0.4959\n",
      "Epoch 98/100\n",
      "1148/1148 [==============================] - 9s 8ms/step - loss: 0.2583 - acc: 0.6586 - val_loss: 2.6629 - val_acc: 0.4954\n",
      "Epoch 99/100\n",
      "1148/1148 [==============================] - 10s 8ms/step - loss: 0.2551 - acc: 0.6593 - val_loss: 2.6676 - val_acc: 0.4962\n",
      "Epoch 100/100\n",
      "1148/1148 [==============================] - 9s 8ms/step - loss: 0.2522 - acc: 0.6601 - val_loss: 2.6674 - val_acc: 0.4954\n"
     ]
    }
   ],
   "source": [
    "z = np.zeros((len(ip_seq),LATENT_DIM))\n",
    "r = model.fit([ip_seq,z,z],one_hot_targets,validation_split=VALIDATION_SPLIT,batch_size=BATCH_SIZE,\n",
    "         epochs=100,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(r.history['loss'], label='loss')\n",
    "plt.plot(r.history['val_loss'], label='val_loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "input2 = Input(shape=(1,)) # we'll only input one word at a time\n",
    "x = embd_layer(input2)\n",
    "x, h, c = lstm(x, initial_state=[init_h, init_c]) # now we need states to feed back in\n",
    "output2 = dense(x)\n",
    "sampling_model = Model([input2, init_h, init_c], [output2, h, c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx2word = {v:k for k, v in word2idx.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_line():\n",
    "    # initial inputs\n",
    "    np_input = np.array([[ word2idx['<sos>'] ]])\n",
    "    h = np.zeros((1, LATENT_DIM))\n",
    "    c = np.zeros((1, LATENT_DIM))\n",
    "\n",
    "    # so we know when to quit\n",
    "    eos = word2idx['<eos>']\n",
    "\n",
    "    # store the output here\n",
    "    output_sentence = []\n",
    "\n",
    "    for _ in range(max_seq_len):\n",
    "        o, h, c = sampling_model.predict([np_input, h, c])\n",
    "\n",
    "        # print(\"o.shape:\", o.shape, o[0,0,:10])\n",
    "        # idx = np.argmax(o[0,0])\n",
    "        probs = o[0,0]\n",
    "        if np.argmax(probs) == 0:\n",
    "            print(\"wtf\")\n",
    "        probs[0] = 0\n",
    "        probs /= probs.sum()\n",
    "        idx = np.random.choice(len(probs), p=probs)\n",
    "        if idx == eos:\n",
    "            break\n",
    "\n",
    "        # accuulate output\n",
    "        output_sentence.append(idx2word.get(idx, '<WTF %s>' % idx))\n",
    "\n",
    "        # make the next input into model\n",
    "        np_input[0,0] = idx\n",
    "\n",
    "    return ' '.join(output_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<sos> it's poor, 'the she, let's dear, it's she, great, she, \"ile's\n",
      "<sos> 'you 'you i'm dear, everything, walls, great, ain't by by by\n",
      "<sos> (we harmless. great, 'cross 'cross great, the' 'cross 'cross thence thence\n",
      "<sos> stillgoing raining.' dear, dear, walls, walls, aren't great, granny, shouldn't shrill\n",
      "---generate another? [Y/n]---y\n",
      "<sos> 'you've waiting.' there's walls, spectre. she, 'cross great, \"ile's joe, dear,\n",
      "<sos> 'i won't shouldn't important, great, granny, we're- important, great, movement movement\n",
      "<sos> it's out!\" shouldn't great, skeleton. great, 'cross great, 'cross tunnel tunnel\n",
      "<sos> doesn't out!\" she, 'the walls, great, walls, heart. let's 'the street\n",
      "---generate another? [Y/n]---y\n",
      "<sos> i've it's 'the let's great, you're sprung fault mars mars mars\n",
      "<sos> don't raining.' 'as aren't great, she, 'the 'cross misting; important, important,\n",
      "<sos> 'four so- dear, listen. speaking: great, let's great, important, \"ile's said,\n",
      "<sos> let's won't 'it great, it's barb ears ears ears ears ears\n",
      "---generate another? [Y/n]---y\n",
      "<sos> 'you've here?\" let's we're- important, nausicaa, great, signals thicken thicken thicken\n",
      "<sos> i'll don't 'cross everything, great, aren't walls, pipe pipe fire cloud\n",
      "<sos> 'well it. important, aren't granny, listen. spectre. 'i 'cross lapish. great,\n",
      "<sos> 'yes, mother? misting; 'cross she, 'cross great, she, misting; said, mounted\n",
      "---generate another? [Y/n]---y\n",
      "<sos> let's harmless. it's she, let's let's walls, she, great, great, sake,\n",
      "<sos> 'no, it's robinson, important, great, song, 'no, listen. walls, joe, button,\n",
      "<sos> 'yes, 'huh, sake, let's great, great, fair. pipe pipe iron lantern\n",
      "<sos> toffile, couldn't misting; walls, 'cross great, let's walls, aren't great, joe,\n",
      "---generate another? [Y/n]---y\n",
      "<sos> 'as it's 'cross everything, everything, granny, 'i great, 'cross she, joe,\n",
      "<sos> yes, here?\" like: everything, important, great, walls, aren't 'cross aroused 'cross\n",
      "<sos> 'i bones?' 'the aren't great, it's everything, granny, 'cross device. \"ile's\n",
      "<sos> yes, it. !' shouldn't she, great, everything, walls, cider, poem. dissolved,\n",
      "---generate another? [Y/n]---n\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    for _ in range(4):\n",
    "        print(sample_line())\n",
    "    ans = input(\"---generate another? [Y/n]---\")\n",
    "    if ans and ans[0].lower().startswith('n'):\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
